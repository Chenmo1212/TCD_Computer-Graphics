# Individual Report

## My individual contribution part

This part is a description of my individual contribution to the group project.

At the beginning of the group work, I found some interesting topics papers of Computer Graphics at a top Graphics conference in the website(https://kesen.realtimerendering.com/). Through watching the homepage and the full content of these papers, I summarized a short description for every paper I have chosen, and sent them to our WhatsApp Group.

> The papers are:
>
> - **Text2Human**: https://yumingj.github.io/projects/Text2Human.html
>   - Enter a simple text description, you can generate a picture of a person according to the description.
> - **Virtual Sketching**: https://markmohr.github.io/virtual_sketching/ 
>   - You can generate vectorized smooth sketch lines based on hand-drawn sketches and pictures of people.

And then we voted for the top 3 papers we are all interested. After counting the votes of everyone, we finally decided to select three papers `Text2human`, `virtual sketching` and `3d reconnstruction for modeling` as the topics we submitted. Finally, I sent an email to the professor to confirm the topics.

After the professor determined that our topic is `Text2human`, I read this article in depth, and then found the technical advantages and disadvantages mentioned in this article, and found that the parts of pose transfer and virtual try-on are still not well enough, there will be problems with the filling due to the joint distortion and the probability of the color of the clothes. Finally, based on this defect, I found a paper optimized at this level in the top Graphics conference: **Dressing in Order: Recurrent Person Generation for Pose Transfer, Virtual Try-on and Outfit Editing**. And I sent an email to the professor to submit the related papers of the main topic of `Text2human`.

About the Group presentation part, in the first meeting we discussed the assignment of presentation tasks, and I recorded the detailed meeting content in the **Group blog** on blackboard, which contained Task Allocation, Time and some notes. I was responsible for the introduction of the main topic and the part of explaining the thesis I selected. The total time needed to be within 3 minutes and 30 seconds.

On the day before the group presentation, I beautified our group's ppt and uploaded the source file to Blackboard's Group File. On the morning of the presentation, we had a few rehearsals before class.

## Other group-members contribution part

There are 4 people in our group, besides me, the others are: Nitin Frederick(21330025), Weiwei Wan(22301337), Shuo Jia(22301057).

During the whole process of the project, the members of our team get along very harmoniously, and they can hold their own opinions on the progress of the project. They would put forward their ideas at the right time, and they can respond to unreasonable places in a timely manner. They questioned that when everyone completed the content of their own part of the project, although due to the heavy workload of other tasks, sometimes they might not be able to complete it on time, but everyone completed it within the agreed time. Otherwise, hey would quickly fill in their part afterwards.

Everyone's workload is about the same. At the beginning of the group assignment, everyone looks for topics they are interested in, then summarizes their thesis in one or two sentences, and sends the link of the thesis to the group. After the article, start voting selection. After determining the topic later, we will all look for a paper related to the topic, and then study it carefully. In the presentation part, we have a clear division of labor. The division of labor is as follows. For the specific division of labor, I have written a document and put it in the group of blackboard:

- About the topic paper ( 4 mins )
  - Introduction (@Long Pan)
  - Improtance and history (@Weiwei Wan)
  - industry or societal significance (@Nitin)
- About our papers ( 10 mins, 2.5 min each )
  - Paper1: @Nitin
  - Paper2: @Long Pan
  - Paper3: @Weiwei
  - Paper4: @Jia shuo
- Conclusion (1 min)
  - Jia shuo

## Assessment

This project is an unfamiliar topic for our team members, but because the actual application scenarios are familiar to us, we are quite interested in this topic. When the theme of our group was determined, we all read the paper carefully. Although the algorithm in it was difficult for us to understand, after discussions among the group members, the general process was somewhat clearer. At first, when we read this paper, we were amazed at the development of this technology. It is already possible to generate images of the characters we want to try on clothes based on a simple description of a few sentences. After an in-depth understanding of the related papers I selected later, I also have a general understanding of the development of this field. Although the technology of this article we selected has achieved certain achievements, there are still some shortcomings in some aspects. There are some problems that cannot be overcome by the current technology, and some problems that this paper has not yet focused on. 

Through the expansion of this field by the four of us in four different directions, we also have a better understanding of this field during some group meeting discussions. For example, the research paper of **Nitin** group-member used the `VQ-Diffusion` model, this model is well-suited for `text-to-image` generation tasks and it plays a crucial role in the `text2human` topic. Since our focus is on virtual fitting, the resulting image, if it is just a solid color frame of clothes, is not perfect for this project. In **Wan**'s research paper, the `HumanGAN` model can solve this problem very well. For the generated clothing pictures, it is very convenient to replace the material of the clothes, increasing the sense of reality. Jia's research paper is about how to combine clothing pictures with human poses, and named this model **ClothFlow**, this technology is also a very important part of this project.

The paper I studied was further expanded on the basis of them. Because for the same clothes, different dressing orders can produce different styles, and if the virtual try-on is just a rigid combination of clothes pictures, it is obviously impossible to produce this expected effect. The **Dressing in order** model was created to solve this problem. It can make clothes produce different try-on effects according to different dressing orders, which has made great progress for this project to a certain extent.

To sum up, I personally think our project is relatively successful. At first, for a field that everyone is not familiar with, we have some preliminary understanding of this field through a few weeks of research on related technologies. By understanding the advantages and disadvantages of each paper, I gradually realized the progress of the research on this topic in the current environment, and what problems still exist.

During the course of the project, I also learned some things about teamwork. Because we all come from different growth environments, many views and habits are different from each other. Different people are different about what they are good at. Therefore, before the project starts, it is necessary to carefully understand each other's previous strengths. Assigning the right tasks to the right people can not only better complete the tasks, but also allow everyone to achieve something. In addition, some necessary rules can be determined at the beginning. For example, if the assigned task is unreasonable, everyone can argue it; if someone cannot complete the part he / she are responsible for in time, he / she need to inform everyone in advance.